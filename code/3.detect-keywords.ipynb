{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c7a10bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nThis scripts uses a series of keywords to detect\\nif a tweet refers to climate or environmental protests.\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "This scripts uses a series of keywords to detect\n",
    "if a tweet refers to climate or environmental protests.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67c49adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "964a071c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv(path):\n",
    "    \"\"\"\n",
    "    Reads a CSV file and returns a pandas DataFrame object.\n",
    "\n",
    "    Args:\n",
    "    path (str): The file path of the CSV file to read.\n",
    "\n",
    "    Returns:\n",
    "    pandas.DataFrame: The contents of the CSV file as a pandas DataFrame object.\n",
    "    \"\"\"\n",
    "    \n",
    "    return pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4844f3e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_keywords(df, protest_keywords, climate_keywords):\n",
    "    \"\"\"\n",
    "    Detects if any of the given keywords in both lists are present in a row of the input DataFrame.\n",
    "\n",
    "    Args:\n",
    "        df (pandas.DataFrame): The input DataFrame to be searched.\n",
    "        protest_keywords (list): A list of keywords related to protest to search for in the DataFrame.\n",
    "        climate_keywords (list): A list of keywords related to protest to search for in the DataFrame.\n",
    "\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: A new DataFrame with columns indicating whether any of the keywords were present in each row.\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If the input DataFrame is empty or if the keywords list is empty.\n",
    "\n",
    "    Disclaimer: The docstring for this function was written with the help of ChatGPT, a language model trained by OpenAI.\n",
    "\n",
    "    Example:\n",
    "        If we have a DataFrame named 'df' with a column named 'text' that contains text data, and a list of keywords,\n",
    "        we can detect the presence of the keywords in the following way:\n",
    "\n",
    "        >>> keywords = [\"climate change\", \"global warming\", \"environment\"]\n",
    "        >>> df_with_keywords = detect_keywords(df, keywords)\n",
    "        >>> print(df_with_keywords)\n",
    "                text               has_protest_keywords   has_climate_keywords\n",
    "            0   foo bar            False                  False\n",
    "            1   climate protest    True                   True\n",
    "            2   climate bar        False                  True\n",
    "            3   baz protest        True                   False\n",
    "    \"\"\"\n",
    "    if df.empty:\n",
    "        raise ValueError(\"Input DataFrame is empty.\")\n",
    "    if not protest_keywords or not climate_keywords:\n",
    "        raise ValueError(\"Keywords list is empty.\")\n",
    "    \n",
    "\n",
    "    # Join the list of keywords into a regex pattern with the '|' operator and capture groups\n",
    "    def make_pattern(keywords):\n",
    "        \"\"\"\n",
    "        Generates a regular expression pattern that matches any of the provided keywords.\n",
    "\n",
    "        Args:\n",
    "            keywords (list): A list of strings containing the keywords to match.\n",
    "\n",
    "        Returns:\n",
    "            str: A regular expression pattern that matches any of the provided keywords.\n",
    "        \"\"\"\n",
    "        \n",
    "        pattern =  \"|\".join([f'({word.lower()})' for word in keywords])\n",
    "        return pattern\n",
    "    \n",
    "    \n",
    "    # Creates regex patterns for the two sets of keywords\n",
    "    protest_pattern = make_pattern(protest_keywords)\n",
    "    climate_pattern = make_pattern(climate_keywords)\n",
    "\n",
    "    # Use str.contains() to search for the pattern in each row of the DataFrame\n",
    "    has_protest_keywords = df.raw_content.str.contains(protest_pattern, case=False, na=False)\n",
    "    has_climate_keywords = df.raw_content.str.contains(climate_pattern, case=False, na=False)\n",
    "    \n",
    "    # Boolean arithmetic to detect which entries have at least one keyword in both lists\n",
    "    has_both_keywords = (has_protest_keywords) & (has_climate_keywords)\n",
    "    \n",
    "    # Add the boolean results as a new column in the DataFrame\n",
    "    df = df.assign(has_protest_keywords=has_protest_keywords) \\\n",
    "       .assign(has_climate_keywords=has_climate_keywords) \\\n",
    "       .assign(has_both_keywords=has_both_keywords)\n",
    "        \n",
    "    # Now we will discover which were the found tokens as well.\n",
    "    # For eficiency sake, we will do this calculation only on rows where\n",
    "    # a match was found.\n",
    "\n",
    "    \n",
    "    def extract_matches(df, pattern):\n",
    "        \"\"\"\n",
    "        Extracts matches for a regular expression pattern from a pandas DataFrame column.\n",
    "\n",
    "        Args:\n",
    "            df (pandas.DataFrame): The DataFrame containing the text data.\n",
    "            pattern (str): A regular expression pattern to search for in the DataFrame column.\n",
    "\n",
    "        Returns:\n",
    "            list: A list of the matched tokens for each row in the DataFrame.\n",
    "        \"\"\"\n",
    "\n",
    "        # Extract the detected tokens and turns them into a bidiemnsional list\n",
    "        tokens_found = df.raw_content.str.lower().str.extract(pattern)\n",
    "        \n",
    "        # Remove nans. Now we have one array of the found words only\n",
    "        tokens_found = tokens_found.apply(lambda row: [item for item in row if pd.notna(item)], axis=1)\n",
    "        \n",
    "        return tokens_found\n",
    "    \n",
    "    \n",
    "    df_matches = df[(df.has_protest_keywords) & (df.has_climate_keywords) ]\n",
    "    df_no_matches = df[(~df.has_protest_keywords) | (~df.has_climate_keywords)]\n",
    "    \n",
    "    protest_tokens = extract_matches(df_matches, protest_pattern)\n",
    "    climate_tokens = extract_matches(df_matches, climate_pattern)\n",
    "        \n",
    "    df_matches['protest_tokens'] = protest_tokens\n",
    "    df_matches['climate_tokens'] = climate_tokens\n",
    "    \n",
    "    df_no_matches['protest_tokens'] = \"not calculated, as the text didn't match keywords present in both lists\"\n",
    "    df_no_matches['climate_tokens'] = \"not calculated, as the text didn't match keywords present in both lists\"\n",
    "\n",
    "    \n",
    "    return pd.concat([df_matches, df_no_matches])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e762f638",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "\n",
    "    df = read_csv(\"../../output/mvp/2.tweets_with_relative_engagement/concatenated-tweets.csv\")\n",
    "\n",
    "    protest_keywords = [ \"greta\",\n",
    "        \"thunberg\",\n",
    "        \"painting\",\n",
    "        \"soup\",\n",
    "        \"gallery\",\n",
    "        \"mashed\",\n",
    "        \"potatoes\",\n",
    "        \"museum\",\n",
    "        \"Greta Thunberg\",\n",
    "        \"Extinction Rebellion\",\n",
    "        \"Fridays for Future\",\n",
    "        \"Sunrise Movement\",\n",
    "        \"Just Stop Oil\",\n",
    "        \"activism\",\n",
    "        \"activist\",\n",
    "        \"march\",\n",
    "        \"demonstration\",\n",
    "        \"rally\",\n",
    "        \"protest\",\n",
    "        \"manifest\",\n",
    "        \"strike\",\n",
    "    ]\n",
    "\n",
    "    climate_keywords = [\n",
    "        \"climate change\",\n",
    "        \"climate crisis\",\n",
    "        \"global warming\",\n",
    "        \"environment\",\n",
    "        \"climate justice\",\n",
    "        \"renewable energy\",\n",
    "        \"fossil fuels\",\n",
    "        \"carbon emissions\",\n",
    "        \"greenhouse gases\",\n",
    "        \"climate emergency\",\n",
    "        \"climate action\",\n",
    "        \"climate policy\",\n",
    "    ]\n",
    "    \n",
    "    df = detect_keywords(df, protest_keywords, climate_keywords)\n",
    "    \n",
    "    df.to_csv(\"../../output/mvp/3.tweets_with_keyword_detection/tweets-with-keywords.csv\", sep=\"|\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ed92042e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/52/vy6xx2q911l7rd368b7ngb8w0000gn/T/ipykernel_13464/1223724372.py:59: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  has_protest_keywords = df.raw_content.str.contains(protest_pattern, case=False, na=False)\n",
      "/var/folders/52/vy6xx2q911l7rd368b7ngb8w0000gn/T/ipykernel_13464/1223724372.py:60: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  has_climate_keywords = df.raw_content.str.contains(climate_pattern, case=False, na=False)\n",
      "/var/folders/52/vy6xx2q911l7rd368b7ngb8w0000gn/T/ipykernel_13464/1223724372.py:102: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_matches['protest_tokens'] = protest_tokens\n",
      "/var/folders/52/vy6xx2q911l7rd368b7ngb8w0000gn/T/ipykernel_13464/1223724372.py:103: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_matches['climate_tokens'] = climate_tokens\n",
      "/var/folders/52/vy6xx2q911l7rd368b7ngb8w0000gn/T/ipykernel_13464/1223724372.py:105: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_no_matches['protest_tokens'] = \"not calculated, as the text didn't match keywords present in both lists\"\n",
      "/var/folders/52/vy6xx2q911l7rd368b7ngb8w0000gn/T/ipykernel_13464/1223724372.py:106: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_no_matches['climate_tokens'] = \"not calculated, as the text didn't match keywords present in both lists\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9min 57s, sys: 14.8 s, total: 10min 12s\n",
      "Wall time: 10min 16s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb83ae64",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
